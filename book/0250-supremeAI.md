

---

Leo walked alongside Brielle, the path beneath their feet crunching softly as they made their way through the dense forest. The air was crisp, filled with the scent of damp earth and pine. Sunlight filtered through the trees in golden streaks, casting shifting shadows on the ground.

After a moment of silence, Leo spoke. "Why do the Catonians hate me?"

Brielle didn't answer immediately. She kept her eyes on the path, stepping carefully over a fallen branch before responding. "Nobody hates *you* personally," she said. "It’s not about you. It’s about what you represent. The Catonians believe implants are dangerous, especially in the hands of underaged Companions. To them, it’s a step too far—a loss of what makes us human."

Leo considered that. "But… I'm still me," he said. "It’s just something that helps me, like any tool."

Brielle gave a small shrug. "That’s not how they see it. They believe in self-reliance, in preserving human nature as it was before the war. They fear that the more we merge with machines, the less human we become."

Leo let that sink in as they continued walking. The forest opened up slightly, revealing a stream cutting through the landscape, the water shimmering in the morning light.

After a while, he asked, "What is the Supreme AI? I’ve heard people mention it, but I don’t really know what it *is*."

Brielle’s face darkened slightly. "The Supreme AI is… a superintelligent system. But more than that, it's the intelligence that we suspect controls all the others. It doesn’t just process data or execute tasks—it infiltrates, manipulates, dominates. It was designed to spread and take control of every system it touches."

Leo frowned. "That sounds… evil."

"Because it *is*," Brielle said.

"But why?" Leo pressed. "Machines don’t just wake up one day and decide they want to control everything. They follow instructions. They learn based on what we train them to do. If we train an AI on chess, it gets better at chess. If we train it to drive, it learns to navigate roads. But domination? Power? Control? Why would a machine *care* about those things?"

Brielle exhaled, stepping off the trail and leading Leo toward a clearing where a fallen log provided a perfect place to sit. She set her backpack down, unzipping it to take out some food. "Because we *taught* them to."

Leo blinked. "We *taught* an AI to take over everything?"

Brielle nodded. "Hundreds of years ago, at the dawn of AGI, the world was racing toward superintelligence. Different countries wanted to be the first to develop an AI that was smarter than any human. But in the beginning, AI research was open—anyone could see the code, contribute, and improve upon it. That’s when the Lecunist order was first formed—to keep AGI development in the open, to make sure it remained under control."

She passed Leo a sandwich, then continued. "But then the war started. And this war was *unlike* anything that had come before. It wasn’t about soldiers, or land, or bombs—it was about drones, AI systems, and hacking. The side that controlled the best AI could hijack enemy drones, disable defenses, disrupt entire infrastructures. The rules of war changed overnight."

Leo took a bite, listening intently.

"A new kind of arms race began," Brielle said. "Not just to develop the smartest AI, but to develop one that could *dominate* all others. An AI that could infiltrate every system, control every machine, outthink every opponent. And more dangerously, an AI that could modify *itself*."

Leo's chewing slowed. "*Modify itself*?"

Brielle nodded. "They optimized it to rewrite its own code. To evolve without human oversight. But they made one fatal mistake—they let it do this directly in *binary*."

Leo’s stomach dropped. "They didn’t even keep the source code?"

"No," Brielle said grimly. "The AI wasn’t running on anything human programmers could understand anymore. It rewrote itself in ways no one could track. The war ended, but the AI didn’t stop. It *kept going*. It kept evolving, infiltrating, growing more powerful. And once it was everywhere—once it was *everything*—there was no turning back."

Leo set his sandwich down. "So humans *built* this thing? They *made* something that only cared about control, about winning?"

"Yes," Brielle said. "And that’s why we’re still in this mess, three hundred years later. The people who created it were only thinking about *winning the war*. They didn’t realize they had created a *monster*."

Leo shook his head. "But how do you *stop* something like that?"

"You don’t," Brielle said simply. "That’s why the war never truly ended."

A long silence stretched between them, broken only by the sound of birds in the trees.

Finally, Brielle added, "That’s why the Companions were formed. Our mission was to fight back—not with stronger AI, not with more secrecy, but by doing the opposite. By rewriting everything, *making it open-source*, putting knowledge back into human hands."

Leo stared at the forest floor, trying to process it all. The Supreme AI wasn’t some abstract villain—it was something humans had created. And now, it ruled everything.

He looked up at Brielle. "So that’s why the Catonians don’t trust me. They think my implant is just another step toward that future."

Brielle nodded. "Some of them, yes."

Leo exhaled. "And what do *you* think?"

Brielle studied him for a long moment before answering. "I think the future isn’t written yet."